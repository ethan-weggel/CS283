1. Your shell forks multiple child processes when executing piped commands. How does your implementation ensure that all child processes complete before the shell continues accepting user input? What would happen if you forgot to call waitpid() on all child processes?

The shell called `waitpid()` for each child that is forked from the parent process in the `execute_pipeline()` function. This ensures that each process finishes with an exit code before moving on. If the parent never calls `waitpid()` on the child process then they can become zombie processes and the kernel will hold their exit information until the parent does something about it. This can lead to memory leaks. However, it is also important to note that if we don't wait for the child in the parent everything becomes asynchronous. Output form the child processes will start interfering with the next/newer prompts on the screen because our input loop will continue to function.

2. The dup2() function is used to redirect input and output file descriptors. Explain why it is necessary to close unused pipe ends after calling dup2(). What could go wrong if you leave pipes open?

After `dup2()` has redirected a file descriptor the other ends of the pipe are no longer needed for that process. Leaving the pipe open can cause the pipeline to "hang" in the sense that the process will still see an open file descriptor and it will never hit EOF. This can also cause leaks and it is important to make sure to close the ends of the pipe to ensure this doesn't happen.

3. Your shell recognizes built-in commands (cd, exit, dragon). Unlike external commands, built-in commands do not require execvp(). Why is cd implemented as a built-in rather than an external command? What challenges would arise if cd were implemented as an external process?

Changing directories entails modifying the working directory fo the shell process itself (which could be considered the parent process here). An external command would run in a separate child process using fork which wouldn't end up affecting the parent's working directory at all. If CD were external running it would change only the child's directory and would defeat the point of running the command entirely because as soon as the child process exits we are back to the directory we started in with the parent.

4. Currently, your shell supports a fixed number of piped commands (CMD_MAX). How would you modify your implementation to allow an arbitrary number of piped commands while still handling memory allocation efficiently? What trade-offs would you need to consider?

To allow an arbitary number of piped commands while still handling memory allocation efficiently I would likely use realloc or a linked list structure to dynamically allocate memory of each new command_t structure as needed during parsing. That way I could iterate normally through the command line passed into the program but then only allocate what I need as I find need of it in the command c-string. The things I would need to consider is size and speed. The fixed-sized approach ensures that we would never exceed a certain size and that it will run relatively the same speed (or is capped as a max elapsed time) per command. With the size allocation approach as well, I would need to ensure that nothing nefarious occurs when parsing the commands and allocating memory. If someone was crafty enough they could put an "infinitely long" command and essentailly ddos the system. I would need to ensure that a stack overflow would not occur and I would need to ensure I don't run out of heap memory which would require some extra helper functions to verify and validate my memory allocation which could slow the system down.